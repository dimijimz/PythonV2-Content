{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ **Advanced Data Analysis Assignment**\n",
                "\n",
                "Welcome to the next-level assignment! We‚Äôll build on the two previous datasets:\n",
                "1. A **region-based** dataset containing `Region`, `Sales`, and `Transactions`.\n",
                "2. A **time-series** dataset containing daily `Sales` from 2020-01-01 to 2020-12-31.\n",
                "\n",
                "In this notebook, you will:\n",
                "1. Load and explore both datasets.\n",
                "2. Perform advanced grouping and pivoting on the regional data.\n",
                "3. Check correlations and detect potential outliers.\n",
                "4. Conduct advanced time-series analysis (rolling means & seasonal decomposition).\n",
                "5. Provide concise insights from your findings.\n",
                "\n",
                "Let's get started! üéâ\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß© **Part A: Advanced Analysis on Regional Sales Data**\n",
                "We'll begin by re-generating (or reloading) the regional sales data from your previous assignment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'pandas'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Part A: Data Generation (Regional) ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Seed for reproducibility\u001b[39;00m\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
                    ]
                }
            ],
            "source": [
                "# === Part A: Data Generation (Regional) ===\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Seed for reproducibility\n",
                "np.random.seed(0)\n",
                "\n",
                "# Generate random data\n",
                "data_regional = {\n",
                "    'Region': np.random.choice(['North', 'South', 'East', 'West'], size=100),\n",
                "    'Sales': np.random.rand(100) * 1000,  # Sales figures between 0 and 1000\n",
                "    'Transactions': np.random.randint(1, 100, size=100)  # Transactions between 1 and 100\n",
                "}\n",
                "\n",
                "# Create DataFrame\n",
                "df_regional = pd.DataFrame(data_regional)\n",
                "df_regional.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîç **Task A1: Exploratory Data Analysis**\n",
                "1. Display basic summary statistics for `Sales` and `Transactions`.\n",
                "2. Identify the number of unique regions.\n",
                "3. Check for any missing values.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df_regional' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === SOLUTION for Task A1 ===\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1) Basic summary statistics\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m summary_stats \u001b[38;5;241m=\u001b[39m \u001b[43mdf_regional\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactions\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_stats)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 2) Number of unique regions\u001b[39;00m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'df_regional' is not defined"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task A1 ===\n",
                "\n",
                "# 1) Basic summary statistics\n",
                "summary_stats = df_regional[['Sales', 'Transactions']].describe()\n",
                "print(summary_stats)\n",
                "# 2) Number of unique regions\n",
                "print(\"\\nNumber of unique regions:\", df_regional['Region'].nunique())\n",
                "# 3) Check for missing values\n",
                "print(\"\\nMissing values:\")\n",
                "print(df_regional.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üíπ **Task A2: Pivot Table & Group Analysis**\n",
                "1. Create a pivot table showing the **average Sales** and **average Transactions** by `Region`.\n",
                "2. Sort the pivot table by the highest average Sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "             Sales  Transactions\n",
                            "Region                          \n",
                            "North   529.015150     52.857143\n",
                            "East    529.009741     48.777778\n",
                            "South   471.744216     47.125000\n",
                            "West    456.467124     48.074074"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === SOLUTION for Task A2 ===\n",
                "\n",
                "# Sort by highest average Sales\n",
                "df_regional.groupby('Region').mean().sort_values('Sales', ascending=False)\n",
                "print(\"\\nSales by Region:\\n\", df_regional.groupby('Region').mean())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚öóÔ∏è **Task A3: Correlation & Outlier Detection** ‚ö†Ô∏è Optional Challenge\n",
                "1. Calculate the correlation between `Sales` and `Transactions`. Do they appear to be correlated?\n",
                "2. Detect potential outliers in `Sales` using the **IQR** (Interquartile Range) method.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Correlation between Sales and Transactions: 0.02608647690406796\n",
                            "Interquartile Range (IQR):  472.77253628765936\n",
                            "Lower Bound:  -451.67072297512066\n",
                            "Upper Bound:  1440.3193439957407\n",
                            "\n",
                            "Number of outliers in 'Sales':  0\n"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === SOLUTION for Task A3 ===\n",
                "# 1) Correlation\n",
                "corr_value = df_regional['Sales'].corr(df_regional['Transactions'])\n",
                "print(\"Correlation between Sales and Transactions:\", corr_value)\n",
                "\n",
                "# 2) Outlier Detection using IQR\n",
                "Q1 = df_regional['Sales'].quantile(0.25)\n",
                "Q3 = df_regional['Sales'].quantile(0.75)\n",
                "IQR = Q3 - Q1\n",
                "lower_bound = Q1 - 1.5 * IQR\n",
                "upper_bound = Q3 + 1.5 * IQR\n",
                "print(\"Interquartile Range (IQR): \", IQR)\n",
                "print(\"Lower Bound: \", lower_bound)\n",
                "print(\"Upper Bound: \", upper_bound)\n",
                "\n",
                "outliers = df_regional[(df_regional['Sales'] < lower_bound) | (df_regional['Sales'] > upper_bound)]\n",
                "print(\"\\nNumber of outliers in 'Sales': \", len(outliers))\n",
                "outliers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìà **Part B: Advanced Time-Series Analysis**\n",
                "Now let's work with the **time-series** dataset from your second assignment. We'll generate (or reload) the data below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === Part B: Data Generation (Time-Series) ===\n",
                "dates = pd.date_range(start=\"2020-01-01\", end=\"2020-12-31\", freq=\"D\")\n",
                "data_timeseries = {\n",
                "    \"Date\": dates,\n",
                "    \"Sales\": (\n",
                "        np.random.rand(len(dates)) * 200\n",
                "        + np.sin(np.linspace(-3, 3, len(dates))) * 50\n",
                "        + 100\n",
                "    ),\n",
                "}\n",
                "\n",
                "df_timeseries = pd.DataFrame(data_timeseries)\n",
                "df_timeseries.set_index(\"Date\", inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîé **Task B1: Quick Exploration**\n",
                "1. Display the first 5 rows.\n",
                "2. Show a statistical summary of the `Sales` column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "                Sales\n",
                            "Date                \n",
                            "2020-01-01  152.405767\n",
                            "2020-01-02  139.541474\n",
                            "2020-01-03  143.935398\n",
                            "2020-01-04  155.644670\n",
                            "2020-01-05  158.496538"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === SOLUTION for Task B1 ===\n",
                "# 1) Display first 5 rows\n",
                "df_timeseries.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "count    366.000000\n",
                            "mean     179.211239\n",
                            "std       24.897467\n",
                            "min      115.418960\n",
                            "25%      160.485854\n",
                            "50%      179.913413\n",
                            "75%      197.478627\n",
                            "max      233.690058\n",
                            "Name: Sales, dtype: float64"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 2) Statistical summary of the 'Sales' column\n",
                "df_timeseries['Sales'].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìÜ **Task B2: Monthly & Rolling Analysis**\n",
                "1. Calculate monthly average `Sales`.\n",
                "2. Compute a 7-day rolling average to smooth out short-term fluctuations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Month\n",
                            "2020-01    174.699406\n",
                            "2020-02    175.596625\n",
                            "2020-03    183.505658\n",
                            "2020-04    176.384074\n",
                            "2020-05    177.133933\n",
                            "2020-06    183.014605\n",
                            "2020-07    176.209166\n",
                            "2020-08    178.908697\n",
                            "2020-09    184.011963\n",
                            "2020-10    181.076129\n",
                            "2020-11    183.828993\n",
                            "2020-12    180.918229\n",
                            "Freq: M, Name: Sales, dtype: float64"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === SOLUTION for Task B2 ===\n",
                "# 1) Monthly average Sales\n",
                "df_timeseries['Month'] = df_timeseries.index.to.period('M')\n",
                "monthly_avg_sales = df_timeseries.groupby('Month')['Sales'].mean()\n",
                "monthly_avg_sales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df_timeseries' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2) 7-day rolling average\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_timeseries[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRolling_7\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_timeseries\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      3\u001b[0m df_timeseries[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRolling_7\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'df_timeseries' is not defined"
                    ]
                }
            ],
            "source": [
                "# 2) 7-day rolling average\n",
                "df_timeseries['Rolling_7'] = df_timeseries['Sales'].rolling(window=7).mean()\n",
                "df_timeseries['Rolling_7'].dropna()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üî¨ **Task B3: Day-of-Week Seasonality Analysis (Using Pandas Only)**\n",
                "\n",
                "1. **Extract the day of the week** from the index and store it in a new column (e.g., `DayOfWeek`).\n",
                "2. **Group by** this `DayOfWeek` column to get the **average Sales** for each day of the week.\n",
                "3. **Compare** these daily averages to see if certain days have higher or lower sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === SOLUTION for Task B3 with Pandas Only ===\n",
                "# 1) Extract day of the week: Monday=0, Sunday=6\n",
                "df_timeseries['DayOfWeek'] = df_timeseries.index.dayofweek\n",
                "# 2) Group by the day of the week to compute average sales\n",
                "dayofweek_means = df_timeseries.groupby('DayOfWeek')['Sales'].mean()\n",
                "\n",
                "print(\"Average Sales by Day of the Week (0=Monday, 6=Sunday):\")\n",
                "print(dayofweek_means)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìù **Observations & Insights**\n",
                "1. **Regional Data**\n",
                "   - The correlation between `Sales` and `Transactions` is quite low, suggesting they‚Äôre not strongly related in this sample.\n",
                "   - Pivot tables show which region averages the highest Sales, with minimal outliers in `Sales`.\n",
                "\n",
                "2. **Time-Series Data**\n",
                "   - The monthly averages reveal slight fluctuations each month.\n",
                "   - The 7-day rolling average smooths out daily noise.\n",
                "   - Seasonal decomposition indicates a clear weekly seasonal pattern (due to the `np.sin()` component) and an overall trend.\n",
                "\n",
                "---\n",
                "## üèÅ **Assignment Wrap-Up**\n",
                "\n",
                "üéâ **Congratulations!** You‚Äôve:\n",
                "- Built pivot tables and looked for regional trends.\n",
                "- Analyzed correlation and outliers.\n",
                "- Explored monthly averages in time-series data.\n",
                "- Investigated rolling averages and seasonal decomposition.\n",
                "\n",
                "These techniques will provide a solid foundation for more advanced analytical work, including forecasting, anomaly detection, and deeper business intelligence. Keep exploring!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
